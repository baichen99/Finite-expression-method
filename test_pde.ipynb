{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pde import LHS_pde, RHS_pde, true_solution, generate_boundary_points, cal_l2_relative_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, dim_in, dim_hidden, dim_out):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(dim_in, dim_hidden)\n",
    "        self.linear2 = torch.nn.Linear(dim_hidden, dim_hidden)\n",
    "        self.linear3 = torch.nn.Linear(dim_hidden, dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.linear1(x))\n",
    "        x = torch.tanh(self.linear2(x))\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pinn train\n",
    "def pinn_train(model, optimizer, dim_set, epoch, num_bd_pts, num_interior_pts, num_test_pts, right, left):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    # interior points\n",
    "    x_interior = torch.rand(num_interior_pts, dim_set) * (right - left) + left\n",
    "    x_interior.requires_grad = True\n",
    "    y_interior = model(x_interior)\n",
    "    LHS_interior = LHS_pde(y_interior, x_interior, dim_set)\n",
    "    RHS_interior = RHS_pde(x_interior)\n",
    "    loss_interior = torch.mean((LHS_interior - RHS_interior)**2)\n",
    "    # boundary points\n",
    "    x_boundary = generate_boundary_points(num_bd_pts, dim_set, right, left)\n",
    "    x_boundary.requires_grad = True\n",
    "    y_boundary = model(x_boundary)\n",
    "    LHS_boundary = LHS_pde(y_boundary, x_boundary, dim_set)\n",
    "    RHS_boundary = RHS_pde(x_boundary)\n",
    "    loss_boundary = torch.mean((LHS_boundary - RHS_boundary)**2)\n",
    "\n",
    "    # loss\n",
    "    loss = loss_interior + 100 * loss_boundary\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # print\n",
    "    if epoch % 100 == 0:\n",
    "        # cal l2 error\n",
    "        x_test = torch.rand(num_test_pts, dim_set) * (right - left) + left\n",
    "        y_test = model(x_test)\n",
    "        true_test = true_solution(x_test)\n",
    "        l2_error = cal_l2_relative_error(y_test, true_test)\n",
    "        print('epoch: %d, loss: %.4e, l2_error: %.4e' % (epoch, loss.item(), l2_error.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 4.2209e+02, l2_error: 5.7386e-01\n",
      "epoch: 100, loss: 1.3926e+01, l2_error: 4.8070e+00\n",
      "epoch: 200, loss: 4.2048e+00, l2_error: 4.9405e+00\n",
      "epoch: 300, loss: 2.5853e+00, l2_error: 5.0906e+00\n",
      "epoch: 400, loss: 1.9050e+00, l2_error: 5.3034e+00\n",
      "epoch: 500, loss: 1.3585e+00, l2_error: 5.5064e+00\n",
      "epoch: 600, loss: 7.8554e-01, l2_error: 5.7232e+00\n",
      "epoch: 700, loss: 7.5676e-01, l2_error: 5.8709e+00\n",
      "epoch: 800, loss: 6.5538e-01, l2_error: 5.9516e+00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epoch):\n\u001b[0;32m---> 14\u001b[0m     pinn_train(model, optimizer, dim_set, epoch, num_bd_pts, num_interior_pts, num_test_pts, right, left)\n",
      "Cell \u001b[0;32mIn[36], line 9\u001b[0m, in \u001b[0;36mpinn_train\u001b[0;34m(model, optimizer, dim_set, epoch, num_bd_pts, num_interior_pts, num_test_pts, right, left)\u001b[0m\n\u001b[1;32m      7\u001b[0m x_interior\u001b[39m.\u001b[39mrequires_grad \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      8\u001b[0m y_interior \u001b[39m=\u001b[39m model(x_interior)\n\u001b[0;32m----> 9\u001b[0m LHS_interior \u001b[39m=\u001b[39m LHS_pde(y_interior, x_interior, dim_set)\n\u001b[1;32m     10\u001b[0m RHS_interior \u001b[39m=\u001b[39m RHS_pde(x_interior)\n\u001b[1;32m     11\u001b[0m loss_interior \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean((LHS_interior \u001b[39m-\u001b[39m RHS_interior)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/FEX/pde.py:12\u001b[0m, in \u001b[0;36mLHS_pde\u001b[0;34m(u, x, dim_set)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(dim_set):\n\u001b[1;32m     11\u001b[0m     ux_tem \u001b[39m=\u001b[39m ux[:, i:i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m---> 12\u001b[0m     uxx_tem \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mgrad(ux_tem, x, grad_outputs\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mones(ux_tem\u001b[39m.\u001b[39;49mshape), create_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     13\u001b[0m     uxx[:, i] \u001b[39m=\u001b[39m uxx_tem[:, i]\n\u001b[1;32m     14\u001b[0m LHS \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mtorch\u001b[39m.\u001b[39msum(uxx, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:276\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[39mreturn\u001b[39;00m _vmap_internals\u001b[39m.\u001b[39m_vmap(vjp, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, allow_none_pass_through\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[1;32m    275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 276\u001b[0m     \u001b[39mreturn\u001b[39;00m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    277\u001b[0m         t_outputs, grad_outputs_, retain_graph, create_graph, t_inputs,\n\u001b[1;32m    278\u001b[0m         allow_unused, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train\n",
    "dim_set = 2\n",
    "dim_hidden = 20\n",
    "dim_out = 1\n",
    "num_epoch = 10000\n",
    "num_bd_pts = 100\n",
    "num_interior_pts = 10000\n",
    "num_test_pts = 10000\n",
    "right = 1\n",
    "left = 0\n",
    "model = MLP(dim_set, dim_hidden, dim_out)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "for epoch in range(num_epoch):\n",
    "    pinn_train(model, optimizer, dim_set, epoch, num_bd_pts, num_interior_pts, num_test_pts, right, left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
